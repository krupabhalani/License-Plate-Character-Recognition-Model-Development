{"cells":[{"cell_type":"markdown","metadata":{"id":"QadytD1XLLe2"},"source":["# Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ve8boQW4LLe9"},"outputs":[],"source":["import pandas as pd  # For handling datasets\n","import numpy as np  # For numerical operations\n","import cv2  # For image processing\n","import matplotlib.pyplot as plt  # For visualizing images\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Dense, Dropout, BatchNormalization, Flatten\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","import os"]},{"cell_type":"markdown","metadata":{"id":"TTVt-2wVLLe_"},"source":["# Load CSV Files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KCeJzsjOLLfA"},"outputs":[],"source":["licplate_detection_data = pd.read_csv('Licplatesdetection_train.csv') # Detection dataset\n","licplate_recognition_data = pd.read_csv('Licplatesrecognition_train.csv') # Recognition dataset"]},{"cell_type":"markdown","metadata":{"id":"-7ilvBymLLfB"},"source":["# Display data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DSQWemMMLLfC"},"outputs":[],"source":["# Display the first few rows of each dataset\n","\n","print(\"Detection Data (First 5 Rows):\")\n","print(licplate_detection_data.head())\n","\n","print(\"\\nRecognition Data (First 5 Rows):\")\n","print(licplate_recognition_data.head())"]},{"cell_type":"markdown","metadata":{"id":"6mNkhERhLLfD"},"source":["# Data Analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z02m9a2YLLfE"},"outputs":[],"source":["# Check for missing values in both datasets\n","\n","print(\"Detection Data:\")\n","print(licplate_detection_data.isnull().sum())\n","\n","print(\"\\nRecognition Data:\")\n","print(licplate_recognition_data.isnull().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fQWycLwkLLfF"},"outputs":[],"source":["# all info about both datasets\n","\n","print(licplate_detection_data.info())\n","print()\n","print(licplate_recognition_data.info())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XpFWkO3zLLfG"},"outputs":[],"source":["# Check for duplicate values in both datasets\n","\n","print(licplate_detection_data.duplicated().sum())\n","print(licplate_recognition_data.duplicated().sum())"]},{"cell_type":"markdown","metadata":{"id":"v9oh6aM1LLfH"},"source":["# Data Exploration"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NxS3O2mHLLfH"},"outputs":[],"source":["# Visualize a sample image from the detection dataset\n","\n","sample_img_path = 'license_plates_detection_train/1.jpg'\n","sample_img = cv2.imread(sample_img_path)  # Read the image\n","plt.imshow(cv2.cvtColor(sample_img, cv2.COLOR_BGR2RGB))  # Display the image\n","plt.title(\"Sample Image from Detection Dataset\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yto48wtMLLfH"},"outputs":[],"source":["# Visualize a sample image from the recognition dataset\n","\n","sample_img_path = 'license_plates_recognition_train/0.jpg'\n","sample_img = cv2.imread(sample_img_path)  # Read the image\n","plt.imshow(cv2.cvtColor(sample_img, cv2.COLOR_BGR2RGB))  # Display the image\n","plt.title(\"Sample Image from Recognition Dataset\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"vE58eiBCLLfI"},"source":["# Data Preparation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"63F-ah1TLLfI"},"outputs":[],"source":["# Prepare data for training the character recognition model\n","X_train = []  # To store training images\n","y_train = []  # To store training labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TBXL_3r4LLfJ"},"outputs":[],"source":["# Convert text to numerical labels (alphanumeric encoding)\n","def encode_text(text):\n","    return [ord(char) - 48 if char.isdigit() else ord(char) - 55 for char in text]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0dZ2JU0sLLfL"},"outputs":[],"source":["for idx, row in licplate_recognition_data.iterrows():\n","    # Read and preprocess image\n","    img_path = f\"license_plates_recognition_train/{row['img_id']}\"\n","    img = cv2.imread(img_path)\n","    img = cv2.resize(img, (128, 64))  # Resize to (128x64) for better feature extraction\n","    X_train.append(img)\n","\n","    # Encode text labels\n","    y_train.append(encode_text(row['text']))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fuqIcjgMLLfL"},"outputs":[],"source":["# Convert image data to numpy array and normalize\n","X_train = np.array(X_train) / 255.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hOFGJu7NLLfL"},"outputs":[],"source":["# Pad label sequences to the same length\n","max_label_length = max(len(seq) for seq in y_train)\n","y_train = pad_sequences(y_train, maxlen=max_label_length, padding='post')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NLAim97cLLfM"},"outputs":[],"source":["# One-hot encode labels for all characters\n","y_train = np.array([to_categorical(seq, num_classes=36) for seq in y_train])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ue9rn_p8LLfM"},"outputs":[],"source":["# Split into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"H0ARhbrJLLfM"},"source":["# Model Building"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XitMLsh1LLfN"},"outputs":[],"source":["# Define the CRNN model input\n","inputs = Input(shape=(64, 128, 3))\n","\n","# Convolutional layers for feature extraction\n","x = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","x = BatchNormalization()(x)\n","\n","x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","x = BatchNormalization()(x)\n","\n","x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","x = BatchNormalization()(x)\n","\n","x = Flatten()(x)\n","\n","# Fully connected layer for classification\n","x = Dense(512, activation='relu')(x)\n","x = Dropout(0.5)(x)\n","outputs = Dense(max_label_length * 36, activation='softmax')(x)\n","\n","# Reshape outputs to match the sequence length and character categories\n","outputs = Reshape((max_label_length, 36))(outputs)\n","\n","# Define the model\n","model = Model(inputs=inputs, outputs=outputs)\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Display model summary\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kasw82AGLLfN"},"outputs":[],"source":["# Train the model\n","history = model.fit(X_train, y_train,\n","                    epochs=20, batch_size=32, validation_data=(X_val, y_val))"]},{"cell_type":"markdown","metadata":{"id":"vWIoRegHLLfN"},"source":["# Accuracy of Character Recognition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HgZXJZsKLLfO"},"outputs":[],"source":["# Evaluate the model\n","accuracy = history.history['val_accuracy'][-1]  # Validation accuracy\n","print(f\"Model Validation Accuracy: {accuracy * 100:.2f}%\")"]},{"cell_type":"markdown","metadata":{"id":"G8VK1A51LLfO"},"source":["# Save Final Output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9v6b971jLLfO"},"outputs":[],"source":["# Generate predictions for test data\n","output_data = []\n","test_img_paths = ['test/' + img for img in sorted(os.listdir('test'))]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CpVRjcr1LLfP"},"outputs":[],"source":["for img_path in test_img_paths:\n","    img = cv2.imread(img_path)\n","    img = cv2.resize(img, (128, 64))\n","    img = img / 255.0\n","    img = np.expand_dims(img, axis=0)\n","\n","    prediction = model.predict(img)\n","    predicted_text = ''.join(\n","        [chr(np.argmax(char_vec) + 48 if np.argmax(char_vec) < 10 else np.argmax(char_vec) + 55)\n","         for char_vec in prediction.reshape(max_label_length, 36)]\n","    )\n","    output_data.append({'id': img_path.split('/')[-1], 'text': predicted_text})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pcZut06yLLfP"},"outputs":[],"source":["# Save output to CSV\n","output_df = pd.DataFrame(output_data)\n","output_df.to_csv('output.csv', index=False)\n","print(\"Output saved to output.csv\")"]},{"cell_type":"markdown","metadata":{"id":"dW3OIhpLLLfP"},"source":["# Display the Final Output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V2G8YLAjLLfP"},"outputs":[],"source":["print(\"Sample Output:\")\n","print(output_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4YOsskh3LLfQ"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}